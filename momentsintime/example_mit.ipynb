{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lithops Moments in Time dataset example\n",
    "## Video/image prediction\n",
    "In this notebook we will process video clips from the MiT dataset at scale with Lithops\n",
    "by predicting the actions with a pretrained ResNet50 model and then counting how many\n",
    "occurrences of each category have been predicted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import builtins\n",
    "import torch.optim\n",
    "import torch.nn.parallel\n",
    "from torch import save, load\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from utils import extract_frames\n",
    "from models import load_model, load_transform, load_categories\n",
    "\n",
    "#from lithops.multiprocessing import Pool, Queue\n",
    "#from lithops.multiprocessing.util import get_uuid\n",
    "from multiprocessing import Pool, Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backends\n",
    "The same program can be run in a local environtment with processes or executed by\n",
    "functions in the cloud. After we choose a backend, only a few file locations must\n",
    "be changed. In this example we will be using the cloud functions backend.\n",
    "\n",
    "We will be using a custom runtime for our functions which has torch, torchvision,\n",
    "ffmpeg and opencv-python modules already installed.\n",
    "We will store the pretrained weights in the cloud so that functions can access it.\n",
    "Then, after functions get the models weights they will start preprocessing input\n",
    "videos and inferring them one by one.\n",
    "  \n",
    "Later in this notebook, we will see a little improvement detail to this process.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_EXEC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = 'momentsintime/input_data'\n",
    "\n",
    "if LOCAL_EXEC:\n",
    "    import os\n",
    "    from builtins import open\n",
    "    pool_initargs = {\n",
    "        'compute_backend': 'localhost',\n",
    "        'storage_backend': 'localhost'\n",
    "        }\n",
    "    weights_location = '/dev/shm/model_weights'\n",
    "    INPUT_DATA_DIR = os.path.abspath(INPUT_DATA_DIR)\n",
    "\n",
    "else:\n",
    "    from lithops.cloud_proxy import os, open\n",
    "    pool_initargs = {\n",
    "        'compute_backend': 'ibm_cf',\n",
    "        'storage_backend': 'ibm_cos',\n",
    "        'runtime': 'dhak/pywren-runtime-pytorch:3.6',\n",
    "        'runtime_memory': 2048\n",
    "        }\n",
    "    weights_location = 'momentsintime/models/model_weights'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_locations = [os.path.join(INPUT_DATA_DIR, name) for name in os.listdir(INPUT_DATA_DIR)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have masked the `open` function and `os` module with a proxy\n",
    "to manage files from the cloud transparently.  \n",
    "We will use `builtins.open` from now on to explicitly access a local file as some accesses have to occur in the very same machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pretrained ResNet50 model weights and save them in a directory accessible by all functions (`weights_location`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_URL = 'http://moments.csail.mit.edu/moments_models'\n",
    "WEIGHTS_FILE = 'moments_RGB_resnet50_imagenetpretrained.pth.tar'\n",
    "\n",
    "if not os.access(WEIGHTS_FILE, os.R_OK):\n",
    "    os.system('wget ' + '/'.join([ROOT_URL, WEIGHTS_FILE]))\n",
    "\n",
    "with builtins.open(WEIGHTS_FILE, 'rb') as f_in:\n",
    "    weights = f_in.read()\n",
    "with open(weights_location, 'wb') as f_out:\n",
    "    f_out.write(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video prediction and reduce function code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SEGMENTS = 16\n",
    "\n",
    "# Get dataset categories\n",
    "categories = load_categories()\n",
    "\n",
    "# Load the video frame transform\n",
    "transform = load_transform()\n",
    "\n",
    "def predict_videos(queue, video_locations):\n",
    "    print('load weights')\n",
    "    with open(weights_location, 'rb') as f:\n",
    "        model = load_model(f)\n",
    "    model.eval()\n",
    "    print('ok')\n",
    "\n",
    "\n",
    "    results = []\n",
    "    local_video_loc = 'video_to_predict_{}.mp4'.format(get_uuid())\n",
    "\n",
    "    for video_loc in video_locations:\n",
    "        print(video_loc)\n",
    "        start = time.time()\n",
    "        with open(video_loc, 'rb') as f_in:\n",
    "            with builtins.open(local_video_loc, 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "\n",
    "        # Obtain video frames\n",
    "        print('extract frames')\n",
    "        frames = extract_frames(local_video_loc, NUM_SEGMENTS)\n",
    "\n",
    "        # Prepare input tensor [num_frames, 3, 224, 224]\n",
    "        print('???')\n",
    "        input_v = torch.stack([transform(frame) for frame in frames])\n",
    "\n",
    "        # Make video prediction\n",
    "        with torch.no_grad():\n",
    "            print('predict')\n",
    "            logits = model(input_v)\n",
    "            h_x = F.softmax(logits, 1).mean(dim=0)\n",
    "            probs, idx = h_x.sort(0, True)\n",
    "\n",
    "        # Output the prediction\n",
    "        result = dict(key=video_loc)\n",
    "        result['prediction'] = (idx[0], round(float(probs[0]), 5))\n",
    "        result['iter_duration'] = time.time() - start\n",
    "        results.append(result)\n",
    "    queue.put(results)\n",
    "\n",
    "# Counts how many predictions of each category have been made\n",
    "def reduce(queue, n):\n",
    "    pred_x_categ = {}\n",
    "    for categ in categories:\n",
    "        pred_x_categ[categ] = 0\n",
    "\n",
    "    checkpoint = 0.2\n",
    "    res_count = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        results = queue.get()\n",
    "        res_count += len(results)\n",
    "        for res in results:\n",
    "            idx, prob = res['prediction']\n",
    "            pred_x_categ[categories[idx]] += 1\n",
    "\n",
    "        # print progress\n",
    "        if i >= (N * checkpoint):\n",
    "            print('Processed {} results.'.format(res_count))\n",
    "            checkpoint += 0.2\n",
    "\n",
    "    return pred_x_categ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map functions\n",
    "Similar to the `multiprocessing` module API, we use a Pool to map the video keys\n",
    "across n workers (concurrency). However, we do not have to instantiate a Pool of\n",
    "n workers *specificly*, it is the map function that will invoke as many workers according\n",
    "to the length of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCURRENCY = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e87407c25a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_videos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpred_x_categ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-67786e7e5288>\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(queue, n)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mres_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "queue = Queue()\n",
    "pool = Pool(initargs=pool_initargs)\n",
    "\n",
    "# Slice data keys\n",
    "N = min(CONCURRENCY, len(video_locations))\n",
    "iterable = [(queue, video_locations[n::CONCURRENCY]) \n",
    "            for n in range(N)]\n",
    "\n",
    "# Map and reduce on the go\n",
    "start = time.time()\n",
    "pool.map_async(func=predict_videos, iterable=iterable)\n",
    "pred_x_categ = reduce(queue, N)\n",
    "end = time.time()\n",
    "    \n",
    "print('\\nDone.')\n",
    "print('Videos processed:', len(video_locations))\n",
    "print('Total duration:', round(end - start, 2), 'sec\\n')\n",
    "\n",
    "for categ, count in pred_x_categ.items():\n",
    "    if count != 0:\n",
    "        print('{}: {}'.format(categ, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "## Performance improvement\n",
    "Now, since we know every function will have to pull the model weights from\n",
    "the cloud storage, we can actually pack these weights with the runtime image\n",
    "and reduce the start-up cost substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_initargs['runtime'] = 'dhak/pywren-runtime-resnet'\n",
    "weights_location = '/momentsintime/model_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_videos(queue, video_locations):\n",
    "    # force local file access on new weights_location\n",
    "    with builtins.open(weights_location, 'rb') as f:\n",
    "        model = load_model(f)\n",
    "    model.eval()\n",
    "\n",
    "    results = []\n",
    "    local_video_loc = 'video_to_predict_{}.mp4'.format(get_uuid())\n",
    "\n",
    "    for video_loc in video_locations:\n",
    "        start = time.time()\n",
    "        with open(video_loc, 'rb') as f_in:\n",
    "            with builtins.open(local_video_loc, 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "\n",
    "        # Obtain video frames\n",
    "        frames = extract_frames(local_video_loc, NUM_SEGMENTS)\n",
    "\n",
    "        # Prepare input tensor [num_frames, 3, 224, 224]\n",
    "        input_v = torch.stack([transform(frame) for frame in frames])\n",
    "\n",
    "        # Make video prediction\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_v)\n",
    "            h_x = F.softmax(logits, 1).mean(dim=0)\n",
    "            probs, idx = h_x.sort(0, True)\n",
    "\n",
    "        # Output the prediction\n",
    "        result = dict(key=video_loc)\n",
    "        result['prediction'] = (idx[0], round(float(probs[0]), 5))\n",
    "        result['iter_duration'] = time.time() - start\n",
    "        results.append(result)\n",
    "    queue.put(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queue = Queue()\n",
    "pool = Pool(initargs=pool_initargs)\n",
    "\n",
    "# Slice data keys\n",
    "N = min(CONCURRENCY, len(video_locations))\n",
    "iterable = [(queue, video_locations[n::CONCURRENCY]) \n",
    "            for n in range(N)]\n",
    "\n",
    "# Map and reduce on the go\n",
    "start = time.time()\n",
    "r = pool.map_async(func=predict_videos, iterable=iterable)\n",
    "pred_x_categ = reduce(queue, N)\n",
    "end = time.time()\n",
    "    \n",
    "print('\\nDone.')\n",
    "print('Videos processed:', len(video_locations))\n",
    "print('Total duration:', round(end - start, 2), 'sec\\n')\n",
    "\n",
    "for categ, count in pred_x_categ.items():\n",
    "    if count != 0:\n",
    "        print('{}: {}'.format(categ, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(weights_location)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove(WEIGHTS_FILE)\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerfiles and build scripts for both runtimes can be found in the runtime/ folder.\n",
    "\n",
    "### Source code adapted from the demonstration in https://github.com/zhoubolei/moments_models\n",
    "\n",
    "### Moments in Time article: http://moments.csail.mit.edu/#paper\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "f80bac9d21cfc353a70444ca9faaf481f2e380c5cbd93faca475aa438e68600b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}